{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IST736 Text Mining\n",
    "## Homework 6\n",
    "### Martin Alonso\n",
    "### 2019-02-23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "For this assignment, we will revisit the week 4 homework and review customer classification using both Bernoulli and Multinomial Naive Bayes from the sklearn package to determine whether a customer is truthful or not and whether the review is good or bad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "import os\n",
    "import re\n",
    "import arff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll first start by reading the arff data and extracting the sentiment, veracity, and text from the data\n",
    "data = arff.load(open('C:/Users/malon/Documents/Syracuse University/IST 736 Text Mining/IST736/IST736/Week4/deception_data_converted_arff.arff'))\n",
    "\n",
    "# Extract the data into a list. \n",
    "data_texts = list(data.values())[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    lie sentiment                                             review\n",
      "0  fake  negative  Mike's Pizza High Point, NY Service was very s...\n",
      "1  fake  negative  i really like this buffet restaurant in Marsha...\n",
      "2  fake  negative  After I went shopping with some of my friend, ...\n",
      "3  fake  negative  Olive Oil Garden was very disappointing. I exp...\n",
      "4  fake  negative  The Seven Heaven restaurant was never known fo...\n"
     ]
    }
   ],
   "source": [
    "# Initiate empty DataFrame\n",
    "corpus = pd.DataFrame()\n",
    "\n",
    "# Process the data and convert to pandas DataFrame\n",
    "for i in range(0, len(data_texts)):\n",
    "    text = data_texts[i]\n",
    "    text_processed = pd.DataFrame(np.array(text).reshape(-1,3))\n",
    "    corpus = pd.concat((corpus, text_processed), axis=0, ignore_index=True)\n",
    "\n",
    "# Keep column names from original data and print first 5 observations\n",
    "corpus.columns = ['lie', 'sentiment', 'review']\n",
    "print(corpus.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data in a more readable format, we'll do some additional cleaning. We'll first remove any special characters from the review column. Then, we'll have all strings in each vector turned into lower case. Once this is completed, we'll start working with the Bernoulli and Multinomial Naive Bayes models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    lie sentiment                                             review\n",
      "0  fake  negative  mike s pizza high point  ny service was very s...\n",
      "1  fake  negative  i really like this buffet restaurant in marsha...\n",
      "2  fake  negative  after i went shopping with some of my friend  ...\n",
      "3  fake  negative  olive oil garden was very disappointing  i exp...\n",
      "4  fake  negative  the seven heaven restaurant was never known fo...\n"
     ]
    }
   ],
   "source": [
    "# Remove special characters and lower case words \n",
    "for i in range(0, len(corpus)): \n",
    "    corpus.iloc[i, 2] = re.sub('[\\W\\_]', ' ', corpus.iloc[i, 2]).lower()\n",
    "\n",
    "print(corpus.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and Modeling\n",
    "#### Bernoulli Naive Bayes\n",
    "Now that the data has been loaded, we'll build three Naive Bayes Bernoulli models with the following parameters: \n",
    "1. Stop words removed\n",
    "2. Stop words removed and 1-2 ngrams\n",
    "3. Stop words removed, stemming, and 1-2 ngrams  \n",
    "\n",
    "But, before we do that, we must prepare the data by converting the vectors into booleans. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46,  0],\n",
       "       [20, 26]], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. We create a TF-IDF vectorizer that removes stop words\n",
    "cv_1 = CountVectorizer(stop_words='english')\n",
    "\n",
    "X_train = corpus.review\n",
    "y_train = corpus.sentiment\n",
    "\n",
    "X_train = cv_1.fit_transform(X_train)\n",
    "\n",
    "# Initiate the BernoulliNB classifier, run over the X_test set, and print a confusion matrix using the predicted and actual variables \n",
    "bnb = BernoulliNB(binarize=1, alpha=1)\n",
    "bnb.fit(X_train, y_train)\n",
    "\n",
    "pred = bnb.predict(X_train)\n",
    "confusion_matrix(y_train, pred, labels=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good first attempt. The model correctly identifies 46 positive reviews. Overall, the accuracy is 78.3 percent; however, the model has a low specificity when it comes to negative reviews, having a value of 56.5 percent. We'll try to improve upon this value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46,  0],\n",
       "       [28, 18]], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Include 1-2 n-grams into TFIDF Vectorizer\n",
    "cv_2 = CountVectorizer(stop_words='english', ngram_range=[1,2], max_df=0.1)\n",
    "\n",
    "X_train = corpus.review\n",
    "y_train = corpus.sentiment\n",
    "\n",
    "X_train = cv_2.fit_transform(X_train)\n",
    "\n",
    "# Initiate the BernoulliNB classifier, run over the X_test set, and print a confusion matrix using the predicted and actual variables \n",
    "bnb.fit(X_train, y_train)\n",
    "\n",
    "pred = bnb.predict(X_train)\n",
    "confusion_matrix(y_train, pred, labels=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No success. The model still accurately confirms the positive reviews, but has a worse specifity and accuracy after accounting for n-grams. We'll try to correct this by stemming the reviews in the last model, but removing n-grams altogether. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    lie sentiment                                             review  \\\n",
      "0  fake  negative  mike s pizza high point  ny service was very s...   \n",
      "1  fake  negative  i really like this buffet restaurant in marsha...   \n",
      "2  fake  negative  after i went shopping with some of my friend  ...   \n",
      "3  fake  negative  olive oil garden was very disappointing  i exp...   \n",
      "4  fake  negative  the seven heaven restaurant was never known fo...   \n",
      "\n",
      "                                      stemmed_review  \n",
      "0  mike s pizza high point  ny service was very s...  \n",
      "1  i really like this buffet restaurant in marsha...  \n",
      "2  after i went shopping with some of my friend  ...  \n",
      "3  olive oil garden was very disappointing  i exp...  \n",
      "4  the seven heaven restaurant was never known fo...  \n"
     ]
    }
   ],
   "source": [
    "# Initiate stemmer and run through reviews \n",
    "englishStemmer=SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "for i in range(0, len(corpus)): \n",
    "    corpus.loc[i, 'stemmed_review'] = englishStemmer.stem(corpus.iloc[i, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46,  0],\n",
       "       [24, 22]], dtype=int64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Classify over stemmed reviews\n",
    "cv_3 = CountVectorizer(stop_words='english', max_df=0.1)\n",
    "\n",
    "X_train = corpus.stemmed_review\n",
    "y_train = corpus.sentiment\n",
    "\n",
    "X_train = cv_3.fit_transform(X_train)\n",
    "\n",
    "# Initiate the BernoulliNB classifier, run over the X_test set, and print a confusion matrix using the predicted and actual variables \n",
    "bnb.fit(X_train, y_train)\n",
    "\n",
    "pred = bnb.predict(X_train)\n",
    "confusion_matrix(y_train, pred, labels=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model improves slightly, but still not to the point where it is better than the first model. The model has trouble identifying which reviews are negative and why they are negative. Perhaps this can be corrected by using the Multinomial Naive Bayes algorithm. \n",
    "\n",
    "#### Multinomial Naive Bayes\n",
    "We'll run the same three models but this time using the MultinomialNB function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44,  2],\n",
       "       [ 0, 46]], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. We create a TF-IDF vectorizer that removes stop words\n",
    "tfidf_1 = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "X_train = corpus.review\n",
    "y_train = corpus.sentiment\n",
    "\n",
    "X_train = tfidf_1.fit_transform(X_train)\n",
    "\n",
    "# Initiate the BernoulliNB classifier, run over the X_test set, and print a confusion matrix using the predicted and actual variables \n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "\n",
    "pred = mnb.predict(X_train)\n",
    "confusion_matrix(y_train, pred, labels=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right off the bat the Multinomial Naive Bayes algorithm delivers a model accuracy of 97.8 percent, much better than any of the results we've seen from the Bernoulli algorithm. Let's try and improve this model by adding n-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44,  2],\n",
       "       [ 0, 46]], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Include 1-2 n-grams into TFIDF Vectorizer\n",
    "tfidf_2 = TfidfVectorizer(stop_words='english', ngram_range=[1,2], max_df=0.1)\n",
    "\n",
    "X_train = corpus.review\n",
    "y_train = corpus.sentiment\n",
    "\n",
    "X_train = tfidf_2.fit_transform(X_train)\n",
    "\n",
    "# Initiate the BernoulliNB classifier, run over the X_test set, and print a confusion matrix using the predicted and actual variables \n",
    "mnb.fit(X_train, y_train)\n",
    "\n",
    "pred = mnb.predict(X_train)\n",
    "confusion_matrix(y_train, pred, labels=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model shows no improvement when compared to the initial one. Let's try the third option after stemming the reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44,  2],\n",
       "       [ 0, 46]], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Classify over stemmed reviews\n",
    "tfidf_3 = TfidfVectorizer(stop_words='english', max_df=0.1)\n",
    "\n",
    "X_train = corpus.stemmed_review\n",
    "y_train = corpus.sentiment\n",
    "\n",
    "X_train = tfidf_3.fit_transform(X_train)\n",
    "\n",
    "# Initiate the BernoulliNB classifier, run over the X_test set, and print a confusion matrix using the predicted and actual variables \n",
    "mnb.fit(X_train, y_train)\n",
    "\n",
    "pred = mnb.predict(X_train)\n",
    "confusion_matrix(y_train, pred, labels=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "The Multinomial Naive Bayes model has been very difficult to improve after its initial attempt. Despite this, it still proved superior to the three models created by the Bernoulli Naive Bayes models. However, this model is not perfect either, as it is only being tested upon itself given that we are working with a very limited data set. It's imperative that, before we draw any conclusions as to which of the two models is the better one, we try using both models with different parameters on a larger training and testing set; this would allow us to get a better idea of which of the Bernoulli or Multinomial variations of Navie Bayes is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
